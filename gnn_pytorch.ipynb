{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gnn_pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKaM4J2WhL5jk514rA3uTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaZzyMan/Notebook/blob/master/gnn_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfTU-BJhyfOu",
        "outputId": "f647346d-7b65-45ff-d829-bb8f5998b2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Module, Dropout, ReLU, Linear, Softmax\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from read_graph import get_sg_graph\n",
        "from gnn_conv import GCNConv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-88bd4f052388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mread_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_sg_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgnn_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'read_graph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1m_oP625Zwm"
      },
      "source": [
        "class MultiGCN(Module):\n",
        "    def __init__(self, feature_dim=0, dropout=0.4, num_graph=3):\n",
        "        super(MultiGCN, self).__init__()\n",
        "        self.feature_dim = feature_dim\n",
        "        self.act = ReLU()\n",
        "        self.dropout = Dropout(p=dropout)\n",
        "        self.out = Linear(64, 6)\n",
        "        self.num_graph = num_graph\n",
        "        for i in range(num_graph):\n",
        "            exec('self.conv_1_{} = GCNConv(in_channels=self.feature_dim, out_channels=64, improved=False)'.format(i))\n",
        "            exec('self.conv_2_{} = GCNConv(in_channels=64 * 3, out_channels=64, improved=False)'.format(i))\n",
        "        self.pred = Softmax(dim=-1)\n",
        "        self.conv_1 = []\n",
        "        self.conv_2 = []\n",
        "\n",
        "    def forward(self, feature=None, adj_indices=None, adj_values=None, out_indices=None, val_indices=None):\n",
        "        for i in range(self.num_graph):\n",
        "            exec('self.conv_1.append(self.conv_1_{})'.format(i))\n",
        "            exec('self.conv_2.append(self.conv_2_{})'.format(i))\n",
        "        x_out = self.dropout(feature)\n",
        "        x_outs = [self.act(conv(x_out, adj_indice, adj_value))\n",
        "                  for adj_indice, adj_value, conv in zip(adj_indices, adj_values, self.conv_1)]\n",
        "        x_out = torch.cat(x_outs, 1)\n",
        "        x_out = self.dropout(x_out)\n",
        "        x_outs = [self.act(conv(x_out.float(), adj_indice, adj_value))\n",
        "                  for adj_indice, adj_value, conv in zip(adj_indices, adj_values, self.conv_2)]\n",
        "        x_out = self.act(sum(x_outs) / 3)\n",
        "        train_out = torch.index_select(x_out, 0, out_indices)\n",
        "        val_out = torch.index_select(x_out, 0, val_indices)\n",
        "        train_out = self.out(train_out.float())\n",
        "        val_out = self.out(val_out.float())\n",
        "        return self.pred(train_out), self.pred(val_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbD6yIOJ5Z3c"
      },
      "source": [
        "# 参数设置\n",
        "lr = .1\n",
        "l2_reg = 0.\n",
        "epochs = 1000\n",
        "patience = 200\n",
        "dropout = .4\n",
        "\n",
        "# 读取数据\n",
        "labels = pickle.load(open('data/label.pickle', 'rb'))\n",
        "exclude_node = ['32715', '32955', '37779', '37812', '37831', '38504', '39172', '39675', '39981', '39043']\n",
        "for node in exclude_node:\n",
        "    labels.pop(node)\n",
        "num_nodes = len(labels)\n",
        "X = []\n",
        "Y = []\n",
        "for node, label in labels.items():\n",
        "    X.append(node)\n",
        "    Y.append(label)\n",
        "labels = pd.Series(Y, index=X)\n",
        "graphs = get_sg_graph(K=50, feature=['land_cover', 'poi', 'building'], d=1.)\n",
        "\n",
        "tr_farc = .2\n",
        "val_frac = .4\n",
        "# 分层抽样分割训练集和测试集\n",
        "train_set, test_set = model_selection.train_test_split(\n",
        "    labels, train_size=int(num_nodes * tr_farc), test_size=None, stratify=labels\n",
        ")\n",
        "# 将测试集分割份被用于验证和评价测试\n",
        "val_set, test_set = model_selection.train_test_split(\n",
        "    test_set, train_size=int(num_nodes * val_frac), test_size=None, stratify=test_set\n",
        ")\n",
        "# 将标签转为二进制编码\n",
        "bin_encoding = LabelEncoder()\n",
        "train_Y = torch.tensor(bin_encoding.fit_transform(train_set), dtype=torch.long)\n",
        "val_Y = torch.tensor(bin_encoding.fit_transform(val_set), dtype=torch.long)\n",
        "test_Y = torch.tensor(bin_encoding.fit_transform(test_set), dtype=torch.long)\n",
        "\n",
        "features = torch.tensor(graphs[0].node_features(), dtype=torch.float32)\n",
        "adjs = [graph.to_adjacency_matrix(weighted='traffic').tocoo() for graph in graphs]\n",
        "adj_indices = [torch.tensor(np.hstack((A.row[:, None], A.col[:, None])).astype(\"int64\").T, dtype=torch.long) for A in adjs]\n",
        "adj_values = [torch.tensor(A.data) for A in adjs]\n",
        "out_indices = torch.tensor(graphs[0].node_ids_to_ilocs(np.asarray(train_set.index)).astype(\"int64\"), dtype=torch.long)\n",
        "val_indices = torch.tensor(graphs[0].node_ids_to_ilocs(np.asarray(val_set.index)).astype(\"int64\"), dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eElk43XW5Z6E"
      },
      "source": [
        "device = torch.device('cpu')\n",
        "model = MultiGCN(feature_dim=features.shape[1], dropout=dropout, num_graph=len(graphs)).to(device)\n",
        "features = features.to(device)\n",
        "adj_indices = [adj_indice.to(device) for adj_indice in adj_indices]\n",
        "adj_values = [adj_value.to(device) for adj_value in adj_values]\n",
        "out_indices = out_indices.to(device)\n",
        "val_indices = val_indices.to(device)\n",
        "val_Y = val_Y.to(device)\n",
        "train_Y = train_Y.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sURB-rQv5lcu"
      },
      "source": [
        "weight_decay_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias' and \"bn\" not in name)\n",
        "no_decay_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias' or \"bn\" in name)\n",
        "parameters = [{'params': weight_decay_list}, {'params': no_decay_list, 'weight_decay': 0.}]\n",
        "optimizer = torch.optim.Adam(parameters, lr=lr, weight_decay=l2_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POppFcpn5Z1I"
      },
      "source": [
        "best_score = 0.\n",
        "es = 0\n",
        "for epoch in range(1, epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    train_pred_Y, val_pred_Y = model(features, adj_indices, adj_values, out_indices, val_indices)\n",
        "    loss = F.cross_entropy(train_pred_Y, train_Y)\n",
        "    val_loss = F.cross_entropy(val_pred_Y, val_Y)\n",
        "    train_f1 = f1_score(bin_encoding.inverse_transform(train_pred_Y.max(dim=-1).indices),\n",
        "                        bin_encoding.inverse_transform(train_Y), average='micro')\n",
        "    val_f1 = f1_score(bin_encoding.inverse_transform(val_pred_Y.max(dim=-1).indices),\n",
        "                      bin_encoding.inverse_transform(val_Y), average='micro')\n",
        "    print(f'Epoch {epoch}/{epochs}')\n",
        "    print(f'loss: {loss} - F1-micro: {train_f1} - val_loss: {val_loss} - val_F1: {val_f1}')\n",
        "    if val_f1 > best_score:\n",
        "        best_score = val_f1\n",
        "        es = 0\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "    else:\n",
        "        es += 1\n",
        "    if es > patience:\n",
        "        print('Early Stopped.')\n",
        "        break\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}